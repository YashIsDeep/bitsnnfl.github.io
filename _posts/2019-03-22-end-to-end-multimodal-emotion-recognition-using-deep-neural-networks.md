---
layout: post
share: true
title: 'End-to-End Multimodal Emotion Recognition Using Deep Neural Networks (Paper
  ID: 75)'
author:
  name: Rishav
  email: f2016108@pilani.bits-pilani.ac.in
categories:
- CNN
- RNN
- Multimodal Learning
- Emotion Detection
tags:
- Medium
date: 2019-03-22 18:14:17 +0000

---
**Short Introduction:** Automatic affect recognition is a challenging task due to the various modalities emotions can be expressed with. Applications can be found in many domains including multimedia retrieval and humanâ€“computer interaction. In recent years, deep neural networks have been used with great success in determining emotional states. The paper proposes a methodology that uses the audio and visual modality for recognition of emotion. Two separate networks and trained and features are combined for final results. _Please go through the paper thoroughly._

**Paper :** [https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966 "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966")

**Paper ID: 75**

**_Expected Deliverables:_**

1. The main architectures comprises of two subnetworks, one for audio and one for video. This paper falls under the moderate category.
2. Report the result in the with following modifications:
   1. _Only Visual Network_
   2. _Audio + Visual Network_
3. No need to carry out the rest comparisons.
4. **_You may freeze the large layers if you have limited computational capacity._**
5. Report the _confusion matrix ._
6. Dataset : **AFEW (_Different from the paper_** ,**_please contact me to get the dataset)_**
7. **Feel** free to contact me in-case of any doubts.