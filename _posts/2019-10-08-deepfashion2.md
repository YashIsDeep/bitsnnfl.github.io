---
layout: post
share: true
title: 'DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images (Paper ID: 134)'
author:
  name: Parth Patel
  email: f2016150@pilani.bits-pilani.ac.in
categories:
- CNN
- Object Detection
- Landmark estimation
tags:
- Medium
date: 2019-10-08 06:24:58 +0000

---
**Abstract:** Understanding fashion images has been advanced by benchmarks with rich annotations such as DeepFashion, whose labels include clothing categories, landmarks, and consumer-commercial image pairs. However, DeepFashion has nonnegligible issues such as single clothing-item per image, sparse landmarks (4∼8 only), and no per-pixel masks, making it had significant gap from real-world scenarios. We fill in the gap by presenting DeepFashion2 to address these issues. It is a versatile benchmark of four tasks including clothes detection, pose estimation, segmentation, and retrieval. It has 801K clothing items where each item has rich annotations such as style, scale, viewpoint, occlusion, bounding box, dense landmarks (e.g. 39 for ‘long sleeve outwear’ and 15 for ‘vest’), and masks. There are also 873K Commercial-Consumer clothes pairs. The annotations of DeepFashion2 are much larger than its counterparts such as 8× of FashionAI Global Challenge. A strong baseline is proposed, called Match R-CNN, which builds upon Mask R-CNN to solve the above four tasks in an end-to-end manner. Extensive evaluations are conducted with different criterions in DeepFashion2.

**Paper Link:** [https://arxiv.org/abs/1901.07973](https://arxiv.org/abs/1901.07973)

**Guidelines/Tasks:**

1. You have to implement the architecture given in the paper (Fig. 4) using TensorFlow, PyTorch or Keras. Note that its compulsory to implement the FN network and clothes detection and landmark estimation part of the PN network. Segmentation part of PN network and the MN network are optional. Accordingly, you can modify the end-to-end loss function specified on page 5 of the paper.
2. You can vary the no. of fully connected layers in clothes detection stream of PN network and the no. of conv. and deconv. layers in landmark estimation stream of PN network (if you do not have enough compute power). In short, you have the flexibility to tinker with the architecture slightly as far as no. of layers and dimensions of the layers are concerned.
3. You have to use DeepFashion2 dataset ([https://github.com/switchablenorms/DeepFashion2](https://github.com/switchablenorms/DeepFashion2)) for training and validation. Since the train.zip provided by the authors is very large (~10 GB), you can either use a part of it for training OR only download the validation.zip (~2 GB) and divide it into your smaller custom training and validation sets.
4. As shown in the paper, show some demo examples generated by your trained model.
5. Report the AP (average precision) metric (as specified in paper) of your trained model on your validation dataset on both the clothes detection and landmark estimation tasks.

**Side Note:** This paper requires you to be familiar with object detection literature such as RPN (Region Proposal Network), FPN (Feature Pyramid Network) etc.

**ID :** 134
