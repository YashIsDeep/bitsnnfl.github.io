---
layout: post
share: true
title: End-to-End Multimodal Emotion Recognition Using Deep Neural Networks
author:
  name: Rishav
  email: f2016108@pilani.bits-pilani.ac.in
categories:
- Emotion Recognition
- Multimodal Learning
tags:
- Medium
date: 2019-03-22 17:42:16 +0000

---
**Short Introduction:** Automatic affect recognition is a challenging task due to the various modalities emotions can be expressed with. Applications can be found in many domains including multimedia retrieval and humanâ€“computer interaction. In recent years, deep neural networks have been used with great success in determining emotional states. The paper proposes a methodology that uses the audio and visual modality for recognition of emotion. Two separate networks and trained and features are combined for final results.

**Paper:** [https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966 "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966")

**Paper ID: 75**

**_Expected Deliverables:_**

1. Paper falls in the moderate category, the main architecture combines features from two different modalities.
2. Implement the paper and report results in the following cases:
   1. _Use only Audio Network._
   2. _Use only Visual Network._
   3. _Combined Results_
3. No need to do the comparisons, just implement the architectures as mentioned above.
4. **Dataset: RECOLA Dataset.**
5. Report the _confusion matrix._
6. Test on atleast 2 real-life samples not in the dataset.(_Should be easy_ :-) )