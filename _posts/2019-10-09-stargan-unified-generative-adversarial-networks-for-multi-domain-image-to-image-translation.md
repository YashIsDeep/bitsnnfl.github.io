---
layout: post
share: true
title: 'StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (Paper ID: 135)'
author:
  name: Parth Patel
  email: f2016150@pilani.bits-pilani.ac.in
categories:
- GANs
- Image Generation
- Unsupervised Learning
tags:
- Medium
date: 2019-10-09 15:56:44 +0000

---
**Abstract**: Recent studies have shown remarkable success in imageto-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGANâ€™s superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.

**Paper Link:** [https://arxiv.org/pdf/1711.09020.pdf](https://arxiv.org/pdf/1711.09020.pdf)

**Paper ID: 135**

**Guidelines:** 

1. Use Tensorflow, PyTorch or Keras to implement the conditional GAN architecture given in the paper (Fig. 3 and section 7.2).
2. If you are not familiar with Wasserstein GAN, you can skip implementing equation 8 of the paper and instead use equation 1 of the paper (for substitution into the final generator and discriminator objectives, as specified by equations 5 and 6).
3. You can use a single dataset for training: either use CelebA or RaFD. You need not use both the the datasets for training a single model, although you should be able to understand the advantages of doing so, as specified in the paper (section 3.2).
4. No need to compare with other baseline models, as specified in the paper.
5. As shown in the paper, show some demo examples generated by your trained model.
6. In case you are training on RaFD dataset, you can try evaluating your model's performance quantitatively as shown in Table 3 of the paper.

**Side Notes:**
1. For introduction to GANs, refer [https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09](https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09) .

