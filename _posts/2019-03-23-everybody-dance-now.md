---
layout: post
share: true
title: 'Everybody Dance Now (Paper ID: 44)'
author:
  name: Aditi Agarwal
  email: f2016095@pilani.bits-pilani.ac.in
categories:
- Video Translation
- GANs
- Pose Estimation
tags:
- Hard
date: 2019-03-23 11:50:39 +0000

---
**Abstract:** This paper presents a simple method for "do as I do" motion transfer: given a source video of a person dancing we can transfer that performance to a novel (amateur) target after only a few minutes of the target subject performing standard moves. We pose this problem as a per-frame image-to-image translation with spatio-temporal smoothing. Using pose detections as an intermediate representation between source and target, we learn a mapping from pose images to a target subject's appearance. We adapt this setup for temporally coherent video generation including realistic face synthesis.

**Note:** Implementation of this paper will need collection of your own video data according to the specifications. It will also need the knowledge and implementation of multiple components (Image to Image Translation, Pose Estimation, GANs etc.). Attempt this paper only if you are REALLY interested and willing to invest time.

**Paper Link:** [https://arxiv.org/abs/1808.07371v1](https://arxiv.org/abs/1808.07371v1 "https://arxiv.org/abs/1808.07371v1")

**Video Link:** [https://www.youtube.com/watch?v=PCBTZh41Ris](https://www.youtube.com/watch?v=PCBTZh41Ris "https://www.youtube.com/watch?v=PCBTZh41Ris")

**Paper ID: 44**

**Guidelines:**

1. Read the paper thoroughly and understand the concepts.
2. Implement the paper and show the results on a video shot by you.
3. As the paper is inherently hard to implement, leniency will be shown in terms of fancy features like FaceGAN not being implemented.
